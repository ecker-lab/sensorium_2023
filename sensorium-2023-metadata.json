{"@context":{"@language":"en","@vocab":"https://schema.org/","citeAs":"cr:citeAs","column":"cr:column","conformsTo":"dct:conformsTo","cr":"http://mlcommons.org/croissant/","data":{"@id":"cr:data","@type":"@json"},"dataBiases":"cr:dataBiases","dataCollection":"cr:dataCollection","dataType":{"@id":"cr:dataType","@type":"@vocab"},"dct":"http://purl.org/dc/terms/","extract":"cr:extract","field":"cr:field","fileProperty":"cr:fileProperty","fileObject":"cr:fileObject","fileSet":"cr:fileSet","format":"cr:format","includes":"cr:includes","isEnumeration":"cr:isEnumeration","isLiveDataset":"cr:isLiveDataset","jsonPath":"cr:jsonPath","key":"cr:key","md5":"cr:md5","parentField":"cr:parentField","path":"cr:path","personalSensitiveInformation":"cr:personalSensitiveInformation","recordSet":"cr:recordSet","references":"cr:references","regex":"cr:regex","repeated":"cr:repeated","replace":"cr:replace","sc":"https://schema.org/","separator":"cr:separator","source":"cr:source","subField":"cr:subField","transform":"cr:transform","wd":"https://www.wikidata.org/wiki/"},"alternateName":"The dataset for neuroscience predictive models for mouse visual cortex","citeAs":"10.34740/kaggle/dsv/8665612","conformsTo":"http://mlcommons.org/croissant/1.0","license":{"@type":"sc:CreativeWork","name":"Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)","url":"https://creativecommons.org/licenses/by-nc-nd/4.0/"},"distribution":[{"contentUrl":"https://www.kaggle.com/api/v1/datasets/download/pollytur23/sensorium-2023?datasetVersionNumber=3","contentSize":"44.483 KB","md5":"LGvzjwe0nifqKjOR8j2j5Q==","encodingFormat":"application/zip","@id":"archive.zip","@type":"cr:FileObject","name":"archive.zip","description":"Archive containing all the contents of the Sensorium 2023 dataset"},{"includes":"*.zip","containedIn":{"@id":"archive.zip"},"encodingFormat":"application/zip","@id":"application-zip_fileset","@type":"cr:FileSet","name":"application/zip files","description":"application/zip files contained in archive.zip"}],"version":3,"keywords":["subject \u003E health and fitness \u003E health \u003E neuroscience","technique \u003E deep learning","subject \u003E earth and nature \u003E animals","task \u003E regression","subject \u003E science and technology \u003E computer science","subject \u003E science and technology \u003E computer science \u003E programming"],"identifier":"10.34740/kaggle/dsv/8665612","isAccessibleForFree":true,"includedInDataCatalog":{"@type":"sc:DataCatalog","name":"Kaggle","url":"https://www.kaggle.com"},"creator":{"@type":"sc:Person","name":"Polina Turishcheva","url":"/pollytur23","image":"https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png"},"publisher":{"@type":"sc:Organization","name":"Kaggle","url":"https://www.kaggle.com/organizations/kaggle","image":"https://storage.googleapis.com/kaggle-organizations/4/thumbnail.png"},"thumbnailUrl":"https://storage.googleapis.com/kaggle-datasets-images/5192661/8665612/b473ed28d0cf010ec996c48a82f9be87/dataset-card.png?t=2024-06-11-13-35-28","dateModified":"2024-06-11T13:31:02.51","datePublished":"2024-06-11T13:31:30.6110452","@type":"sc:Dataset","name":"Sensorium 2023","url":"https://www.kaggle.com/datasets/pollytur23/sensorium-2023/versions/3","description":"# Data for the \u003Ca href=\u0022https://www.sensorium-competition.net\u0022\u003ESensorium2023\u003C/a\u003E competition\n\n\n**!!! Note: GIN does not support bulk downloads. You need to download the files individually !!!**\n\n**For citation please use doi:10.48550 from the whitepaper**\n\n# Dataset Structure\n\nBelow we provide a brief explanation of the dataset structure and how to access all the information contained in them.\n\nHave a look at our white paper for in depth description of the data. [White paper on arXiv](https://arxiv.org/abs/2305.19654)\n\nWe provide the datasets in the .zip format. Unzipping them will create two folders **data** and **meta**.\n\n- **data:** includes the variables that were recorded during the experiment. The experimental variables are saved as a collection of numpy arrays. Each numpy array contains the value of that variable at a specific image presentation (i.e. trial). Note that the name of the files does not contain any information about the order or time at which the trials took place in experimental time. They are randomly ordered.\n  - **videos:** This directory contains NumPy arrays where each single \u0060X.npy\u0060 contains the video that was shown to the mouse in trial \u0060X\u0060.\n  - **responses:** This directory contains NumPy arrays where each single \u0060X.npy\u0060 contains the deconvolved calcium traces (i.e. responses) recorded from the mouse in trial \u0060X\u0060 in response to the particular presented image.\n  - **behavior:** Behavioral variables include pupil dilation and running speed. The directory contain NumPy arrays (of size \u00601 x 2\u0060) where each single \u0060X.npy\u0060 contains the behavioral variables (in the same order that was mentioned earlier) for trial \u0060X\u0060.\n  - **pupil_center:** the eye position of the mouse, estimated as the center of the pupil. The directory contain NumPy arrays (of size \u00601 x 2\u0060) for horizontal and vertical eye positions.\n- **meta:** includes meta data of the experiment\n    - **neurons:** This directory contains neuron-specific information. Below are a list of important variables in this directory\n        - \u0060cell_motor_coordinates.npy\u0060: contains the position (x, y, z) of each neuron in the cortex, given in microns. **Note:** The\n    - **statistics:** This directory contains statistics (i.e. mean, median, etc.) of the experimental variables (i.e. behavior, images, pupil_center, and responses).\n      - **Note:** The statistics of the responses are or particular importance, because we provide the deconvolved calcium traces here in the responses.\n      \n        However, for the evaluation of submissions in the competition, we require the responses to be **standardized** (i.e. \u0060r = r/(std_r)\u0060).\n        \n    - **trials:** This directory contains trial-specific meta data. \n       \n        - \u0060tiers.npy\u0060: contains labels that are used to split the data into *train*, *validation*, and *test* set\n          - The *training* and *validation* split is only present for convenience, and is used by our ready-to-use PyTorch DataLoaders.\n          - The *test* set is used to evaluate the model preformance. In the competition datasets, the responses to all *test* images is withheld."}